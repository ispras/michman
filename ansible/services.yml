---
- hosts: localhost
  tasks:
    - include_role:
        name: os_facts
      when: act != "destroy"

- name: Import Kubespray deployment playbook
  import_playbook: "{{ 'kubespray-wrapper.yml' if deploy_kubernetes is defined and deploy_kubernetes else 'service-mock.yml' }}"
  when: deploy_kubernetes is defined and deploy_kubernetes

- hosts: all
  become: yes
  tasks:
    - name: Consul
      include_role:
        name: consul
      when: deploy_consul is defined and deploy_consul

    - name: Sleep for 30 seconds and continue with play
      wait_for:
        timeout: 15
      when: deploy_consul is defined and deploy_consul

- hosts: "{{ cluster_name }}_master:{{ cluster_name }}_slaves"
  become: yes
  tasks:
    - name: install Spark
      include_role:
        name: spark_common
      when: deploy_spark is defined and deploy_spark
    - name: install cassandra
      include_role:
        name: cassandra
      when: deploy_cassandra is defined and deploy_cassandra
    - name: prepare ignite
      include_role:
        name: ignite_prepare
      when: deploy_ignite is defined and deploy_ignite
    - name: config ignite
      include_role:
        name: ignite_config
      when: deploy_ignite is defined and deploy_ignite
    - name: mountnfs
      include_role:
        name: mountnfs
      when: mountnfs is defined and mountnfs


- hosts: "{{ cluster_name }}_master:{{ cluster_name }}_slaves"
  tasks:
    - include_role:
        name: tensorflow
      when: deploy_tensorflow is defined and deploy_tensorflow

- hosts: "{{ cluster_name }}_master"
  tasks:
    - include_role:
        name: spark_master
      when: deploy_spark is defined and deploy_spark
    - include_role:
        name: jupyter
      when: deploy_jupyter is defined and deploy_jupyter
    - include_role:
        name: jupyterhub
      vars:
        python_version: 3
      when: deploy_jupyterhub is defined and deploy_jupyterhub
    - include_role:
        name: openfaas
      when: deploy_openfaas is defined and deploy_openfaas

#When create_storage is true, such instance would be created
- hosts: "{{ cluster_name }}_storage"
  become: yes
  roles:
    - { role: network_storage, when: mount_external_storage is defined and mount_external_storage } # nextcloud_nfs_server_ip must be defined
    - { role: nfs_server, when: deploy_nfs_server is defined and deploy_nfs_server}
    - { role: nextcloud, when: deploy_nextcloud is defined and deploy_nextcloud }
    - { role: clickhouse, when: deploy_clickhouse is defined and deploy_clickhouse }
    - { role: couchdb, when: deploy_couchdb is defined and deploy_couchdb }
    - { role: postgresql, when: deploy_postgresql is defined and deploy_postgresql }
    - { role: redis, when: deploy_redis is defined and deploy_redis }
    - { role: mariadb, when: deploy_mariadb is defined and deploy_mariadb}


- hosts: "{{ cluster_name }}_storage"
  become: yes
  tasks:
    - include_role:
        name:  slurm_db
      when: slurm_use_db is defined and slurm_use_db

- hosts: "{{ cluster_name }}_master"
  tasks:
    - include_role:
        name: slurm_master
      when: deploy_slurm is defined and deploy_slurm
    - include_role:
        name: mountnfs
      when: deploy_slurm is defined and deploy_slurm and deploy_nfs_server is defined and deploy_nfs_server

- hosts: "{{ cluster_name }}_slaves"
  tasks:
    - include_role:
        name: slurm_slave
      when: deploy_slurm is defined and deploy_slurm
    - include_role:
        name: mountnfs
      when: deploy_slurm is defined and deploy_slurm and deploy_nfs_server is defined and deploy_nfs_server

- hosts: all
  tasks:
    - include_role:
        name: slurm_openfoam
      when: slurm_use_open_foam is defined and slurm_use_open_foam

- hosts: "{{ cluster_name }}_master"
  tasks:
    - include_role:
        name: slurm_rest
      when: slurm_use_rest is defined and slurm_use_rest

- hosts: "{{ cluster_name }}_master"
  become: yes
  tasks:
    - include_role:
        name: elasticsearch
      vars:
        es_instance_name: "{{ cluster_name }}"
        es_heap_size: "{{ elastic_heap_size }}"
        es_java_install: false
        es_config:
          cluster:
            name: "{{ cluster_name }}"
            initial_master_nodes: "{{ active_master_ip }}"
          http:
            port: 9200
          transport:
            port: 9300
          node:
            data: false
            master: "true"
          network:
            host: "0"
          discovery:
            seed_hosts: "{{ active_master_ip }}"
      when: deploy_elastic is defined and deploy_elastic

- hosts: "{{ cluster_name }}_slaves"
  become: yes
  tasks:
    - include_role:
        name: elasticsearch
      vars:
        es_instance_name: "{{ cluster_name }}"
        es_data_dirs: "/opt/elasticsearch"
        es_java_install: false
        es_config:
          cluster:
            name: "{{ cluster_name }}"
            initial_master_nodes: "{{ active_master_ip }}"
          http:
            port: 9200
          transport:
            port: 9300
          node:
            data: false
            master: "false"
          network:
            host: "0"
          discovery:
            seed_hosts: "{{ active_master_ip }}"
      when: deploy_elastic is defined and deploy_elastic

- hosts: "{{ cluster_name }}_master"
  tasks:
    - include_role:
        name: cvat
      when: deploy_cvat is defined and deploy_cvat

- hosts: "{{ cluster_name }}_master:{{ cluster_name }}_slaves"
  become: yes
  tasks:
    - include_role:
        name: greenplum_installation
      when: deploy_greenplum is defined and deploy_greenplum
    - include_role:
        name: greenplum_setssh
      when: deploy_greenplum is defined and deploy_greenplum

- hosts: "{{ cluster_name }}_master"
  become: yes
  tasks:
    - include_role:
        name: greenplum_run
      when: deploy_greenplum is defined and deploy_greenplum


- hosts: all
  vars:
    ansible_python_interpreter: "/usr/bin/python3"
  tasks:
    - name: Run check.yml instead of 'main'
      become: yes
      import_role:
        name: consul
        tasks_from: check
      when: create_monitoring is defined and create_monitoring
